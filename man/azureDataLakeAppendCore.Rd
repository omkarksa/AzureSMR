% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AzureDataLake.R
\name{azureDataLakeAppendCore}
\alias{azureDataLakeAppendCore}
\title{The Core Append API.}
\usage{
azureDataLakeAppendCore(azureActiveContext, azureDataLakeAccount, relativePath,
  bufferSize, contents, contentSize = -1L, leaseId = NULL,
  sessionId = NULL, syncFlag = NULL, offsetToAppendTo = -1,
  verbose = FALSE)
}
\arguments{
\item{azureActiveContext}{A container used for caching variables used by \code{AzureSMR}, created by \code{\link[=createAzureContext]{createAzureContext()}}}

\item{azureDataLakeAccount}{Name of the Azure Data Lake account.}

\item{relativePath}{Relative path of a file.}

\item{bufferSize}{Size of the buffer to be used.}

\item{contents}{raw contents to be written to the file.}

\item{contentSize}{size of \code{contents} to be written to the file.}

\item{leaseId}{a String containing the lease ID (generated by client). Can be null.}

\item{sessionId}{a String containing the session ID (generated by client). Can be null.}

\item{syncFlag}{Use \code{DATA} when writing more bytes to same file path. Most performant operation.
Use \code{METADATA} when metadata for the
file also needs to be updated especially file length
retrieved from \code{azureDataLakeGetfileStatus} or \code{azureDatalakeListStatus API call. Has an overhead of updating metadata operation. Use}CLOSE` when no more data is
expected to be written in this path. Adl backend would
update metadata, close the stream handle and
release the lease on the
path if valid leaseId is passed.
Expensive operation and should be used only when last
bytes are written.}

\item{offsetToAppendTo}{offset at which to append to to file.
To let the server choose offset, pass \code{-1}.}

\item{verbose}{Print tracing information (default FALSE).}
}
\value{
response object
Exception IOException
}
\description{
The Core Append API.
}
\references{
\url{https://docs.microsoft.com/en-us/azure/data-lake-store/data-lake-store-data-operations-rest-api#upload-data}
}
\seealso{
\url{https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Append_to_a_File}

\url{https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/WebHDFS.html#Buffer_Size}

\url{https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html#append-org.apache.hadoop.fs.Path-int-org.apache.hadoop.util.Progressable-}

Other Azure Data Lake Store functions: \code{\link{adlFileInputStreamAvailable}},
  \code{\link{adlFileInputStreamClose}},
  \code{\link{adlFileInputStreamGetPos}},
  \code{\link{adlFileInputStreamLength}},
  \code{\link{adlFileInputStreamMarkSupported}},
  \code{\link{adlFileInputStreamMark}},
  \code{\link{adlFileInputStreamReadBuffered}},
  \code{\link{adlFileInputStreamRead}},
  \code{\link{adlFileInputStreamReset}},
  \code{\link{adlFileInputStreamSeek}},
  \code{\link{adlFileInputStreamSkip}},
  \code{\link{adlFileOutputStreamClose}},
  \code{\link{adlFileOutputStreamFlush}},
  \code{\link{adlFileOutputStreamWrite}},
  \code{\link{azureDataLakeAppendBOS}},
  \code{\link{azureDataLakeAppend}},
  \code{\link{azureDataLakeCreate}},
  \code{\link{azureDataLakeDelete}},
  \code{\link{azureDataLakeGetFileStatus}},
  \code{\link{azureDataLakeListStatus}},
  \code{\link{azureDataLakeMkdirs}},
  \code{\link{azureDataLakeOpenBIS}},
  \code{\link{azureDataLakeReadCore}},
  \code{\link{azureDataLakeRead}},
  \code{\link{createAdlExponentialBackoffRetryPolicy}},
  \code{\link{createAdlFileInputStream}},
  \code{\link{createAdlFileOutputStream}},
  \code{\link{createAdlNonIdempotentRetryPolicy}},
  \code{\link{createAdlRetryPolicy}},
  \code{\link{readFromService}},
  \code{\link{shouldRetry.adlExponentialBackoffRetryPolicy}},
  \code{\link{shouldRetry.adlNonIdempotentRetryPolicy}},
  \code{\link{shouldRetry}}
}
